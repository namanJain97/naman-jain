import requests
import json
from urllib.parse import quote_plus
import pandas as pd
import concurrent.futures
import asyncio
import aiohttp

def flatten_json(data, prefix=''):
    flattened_data = {}
    if isinstance(data, dict):
        for key, value in data.items():
            new_key = f"{prefix}.{key}" if prefix else key
            if isinstance(value, (dict, list)):
                flattened_data.update(flatten_json(value, new_key))
            else:
                flattened_data[new_key] = value
    elif isinstance(data, list):
        for index, item in enumerate(data):
            new_key = f"{prefix}.{index}" if prefix else str(index)
            if isinstance(item, (dict, list)):
                flattened_data.update(flatten_json(item, new_key))
            else:
                flattened_data[new_key] = item
    else:
        flattened_data[prefix] = data
    return flattened_data


def build_json_response(flattened_data):
    json_response = {}
    for key, value in flattened_data.items():
        nested_keys = key.split('.')
        current_dict = json_response
        for nested_key in nested_keys[:-1]:
            if nested_key not in current_dict:
                current_dict[nested_key] = {}
            current_dict = current_dict[nested_key]

        if nested_keys[-1] == "contents":
            if nested_keys[-2] not in current_dict:
                current_dict[nested_keys[-2]] = []
            current_dict[nested_keys[-2]].append(value)
        else:
            current_dict[nested_keys[-1]] = value
    return json_response


def extract_field_values(data, field_names):
    extracted_values = {}
    for key, value in data.items():
        if isinstance(value, dict):
            nested_values = extract_field_values(value, field_names)
            for nested_key, nested_value in nested_values.items():
                new_key = f"{key}.{nested_key}"
                extracted_values[new_key] = nested_value
        elif not field_names or key in field_names:
            extracted_values[key] = value
    return extracted_values


async def call_api_with_bearer_token(url, access_token, sso_token, request_body=None, where_conditions=None, field_names=None):
    headers = {
        'Authorization': f'Bearer {sso_token}',
        'Content-Type': 'application/json'
    }

    async with aiohttp.ClientSession(headers=headers) as session:
        if request_body:
            headers['accessToken'] = access_token
            async with session.post(url, json=request_body) as response:
                json_data = await response.json()
        elif where_conditions:
            where_encoded = quote_plus(where_conditions)
            query_string = f"where={where_encoded}&accessToken={access_token}"
            async with session.get(f"{url}?{query_string}") as response:
                json_data = await response.json()
        else:
            print("Invalid API call. Please provide either request body or where conditions.")
            return None

    flattened_data = flatten_json(json_data)
    json_response = build_json_response(flattened_data)

    extracted_data = []
    for record in json_response.values():
        field_values = extract_field_values(record, field_names)
        if field_values:
            extracted_data.append(field_values)

    return extracted_data

    except requests.exceptions.RequestException as e:
        print(f"Error occurred: {e}")
    except json.decoder.JSONDecodeError as e:
        print(f"Error decoding JSON response: {e}")
    except Exception as e:
        print(f"An error occurred: {e}")
    
    return None


# First API - Using request body and pagination
url1 = "http://lonrs14597.fm.rbsgrp.net:36124/ignite/trade/regulatory/mas/trade/query"
request_body1 = {
    "select": "",
    "orderBy": None,
    "where": "sourceSystemId = 'GlobalFX GBLO'"
}

# Second API - Using where conditions
url2 = "http://datafabric-tst:40003/datafabric/Tntr-prodprl/TNTR-trade-prodprl"
where_conditions2 = "subjectIdentifier.regulatoryRegimeIdentifier.regulatoryAuthority = 'The Monetary Authority of Singapore'"
field_names2 = []  # Add the field names you want to extract, or leave it empty for all fields

access_token = "b0013b54-b771-43f7-b2e0-a86b51fd92aa"
sso_token = "GNDlXXwmW6Y+b8IgwU7jY6h0ArBY3Ajv2hq2h30QvSg/jTOkglmLKJLSRX5W4UafsNeHJAzLXdnCSr1QHAkrYpICIYLx7mBKdIceuv/gMRAQTxFQyejguVOCoGXje3OmJ2HtnQbsrCAedviwII7ttm82VQTIJy63311sYPbLllo=|0|jainnbr|TNTR-User|20230624161948|18000|"

# Make API calls concurrently and save data into DataFrames
async def call_apis_concurrently():
    async with aiohttp.ClientSession() as session:
        async with session.get(url1) as response1, session.get(url2) as response2:
            json_data1 = await response1.json()
            json_data2 = await response2.json()

    data1 = flatten_json(json_data1)
    data2 = flatten_json(json_data2)

    extracted_data1 = []
    extracted_data2 = []

    with concurrent.futures.ThreadPoolExecutor() as executor:
        futures1 = [executor.submit(extract_field_values, record, None) for record in data1.values()]
        futures2 = [executor.submit(extract_field_values, record, field_names2) for record in data2.values()]

        for future in concurrent.futures.as_completed(futures1):
            extracted_data1.append(future.result())

        for future in concurrent.futures.as_completed(futures2):
            extracted_data2.append(future.result())

    df1 = pd.DataFrame(extracted_data1)
    df2 = pd.DataFrame(extracted_data2)

    # Display the DataFrames
    print("DataFrame 1:")
    print(df1)

    print("DataFrame 2:")
    print(df2)

    # Save the DataFrames to CSV files
#     df1.to_csv("data1.csv", index=False)
#     df2.to_csv("data2.csv", index=False)

# Run the asynchronous code
loop = asyncio.get_event_loop()
loop.run_until_complete(call_apis_concurrently())
